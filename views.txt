from django.shortcuts import render
from django.http import HttpResponse
from django.template import loader


import random
import string
# import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import warnings
warnings.filterwarnings('ignore')
import nltk
from nltk.stem import WordNetLemmatizer
nltk.download('popular', quiet=True)  # for downloading packages
nltk.download('punkt')  # first-time use only
nltk.download('wordnet')  # first-time use only





def index(request):
    template = loader.get_template('app.html')
    con = {}

    if request.method == 'POST':

        user_input = request.POST.get('input')
        chat = request.POST.get('content')
        print(user_input)






        # Reading in the corpus
        with open('app/chats.txt', 'r', encoding='utf8', errors='ignore') as fin:
            raw = fin.read().lower()

        # Tokenisation
        sent_tokens = nltk.sent_tokenize(raw)  # converts to list of sentences
        word_tokens = nltk.word_tokenize(raw)  # converts to list of words

        # lemmer
        # Preprocessing
        lemmer = WordNetLemmatizer()

        def LemTokens(tokens):
            return [lemmer.lemmatize(token) for token in tokens]

        remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)

        def LemNormalize(text):
            return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))

     
        # Generating response
        def response(user_response):
            robo_response = ''
            sent_tokens.append(user_response)
            TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')
            tfidf = TfidfVec.fit_transform(sent_tokens)
            vals = cosine_similarity(tfidf[-1], tfidf)
            idx = vals.argsort()[0][-2]
            flat = vals.flatten()
            flat.sort()
            req_tfidf = flat[-2]
            if (req_tfidf == 0):
                robo_response = robo_response + " > I am sorry I didn`t catched that, but I am constantly learning.. Could you please try to say it in other words?"
                with open('app/userinputs.txt', 'a') as f:
                    f.write(' > '+user_response+'.'+'\n')
                return robo_response
            else:
                robo_response = robo_response + sent_tokens[idx]
                return robo_response



        user_response = user_input.lower()
        res = response(user_response)
        print("FAQ Bot: ", end="")
        print(res)
        res = res.split(">", 1)
        #print(res[1])
        resp = res[1]
        con = {'resp': resp, 'input': user_response}
        sent_tokens.remove(user_response)
        return HttpResponse(template.render(con, request))



    return HttpResponse(template.render(con))
